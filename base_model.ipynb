{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_x = './input_data/trainDF.csv'\n",
    "filename_y = './input_data/trainY.csv'\n",
    "\n",
    "df = pd.read_csv(filename_x).iloc[:, 1:]\n",
    "Y = pd.read_csv(filename_y).iloc[:, 1:]\n",
    "\n",
    "Y = np.argmax(np.array(Y), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use only X1 - X5 to train a simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.23      0.27       673\n",
      "           1       0.34      0.40      0.37       721\n",
      "           2       0.37      0.42      0.39       706\n",
      "\n",
      "    accuracy                           0.35      2100\n",
      "   macro avg       0.35      0.35      0.34      2100\n",
      "weighted avg       0.35      0.35      0.34      2100\n",
      "\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "# remove history sentiment data\n",
    "\n",
    "train = df.loc[:, 'X1':\"X5\"]\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, Y,  \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "\n",
    "parameter_grid = {\"C\":[0.6, 0.7, 0.8, 0.9, 1]}\n",
    "simple_model = GridSearchCV(LogisticRegression(), param_grid=parameter_grid,\n",
    "                            n_jobs=-1)\n",
    "simple_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_valid, simple_model.predict(x_valid)))\n",
    "print(accuracy_score(y_valid, simple_model.predict(x_valid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use all the sentiment data to train a regression model with l1 reguralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.07      0.12       695\n",
      "           1       0.36      0.72      0.48       701\n",
      "           2       0.36      0.29      0.32       704\n",
      "\n",
      "    accuracy                           0.36      2100\n",
      "   macro avg       0.37      0.36      0.30      2100\n",
      "weighted avg       0.37      0.36      0.31      2100\n",
      "\n",
      "0.36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get all history sentiment data\n",
    "sentiment = df.loc[:, 'I1_lag1':'I10_lag47']\n",
    "train = sentiment\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, Y,  \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "\n",
    "parameter_grid = {\"alpha\":[1e-2, 3e-2, 1e-1, 3e-1, 1]}\n",
    "simple_model = GridSearchCV(SGDClassifier(penalty='l1', loss='log'), \n",
    "                            param_grid=parameter_grid,\n",
    "                            n_jobs=-1)\n",
    "simple_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_valid, simple_model.predict(x_valid)))\n",
    "print(accuracy_score(y_valid, simple_model.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use X1-X10, max, min, median, mean, trend of sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:11<00:00,  7.15s/it]\n",
      "C:\\Users\\82091\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.28      0.34       714\n",
      "           1       0.45      0.68      0.54       716\n",
      "           2       0.43      0.38      0.40       670\n",
      "\n",
      "    accuracy                           0.45      2100\n",
      "   macro avg       0.44      0.44      0.43      2100\n",
      "weighted avg       0.44      0.45      0.43      2100\n",
      "\n",
      "0.4461904761904762\n",
      "1.0592293663015067\n"
     ]
    }
   ],
   "source": [
    "def get_trend_of_ts(ts):\n",
    "    '''\n",
    "    get the slope of time series, if the slope is not significant, set it to 0\n",
    "    \n",
    "    input:\n",
    "    -----------------\n",
    "    ts: time series data\n",
    "    \n",
    "    \n",
    "    output:\n",
    "    -----------------\n",
    "    trend[float] (slope)\n",
    "    '''\n",
    "    x = np.arange(0, len(ts))\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(ts, x).fit()\n",
    "    if model.pvalues['x1'] < 0.05:\n",
    "        return model.params['x1']\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "def get_mean_max_min_median_trend_sentiment(df):\n",
    "    '''\n",
    "    get the max value, min value, median value, trend value of all sentiment\n",
    "    \n",
    "    input:\n",
    "    -------------------------------\n",
    "    df[DataFrame]: input data containing sentiment data\n",
    "    \n",
    "    \n",
    "    output:\n",
    "    -------------------------------\n",
    "    max value, min value, median value, trend value of all sentiment\n",
    "    \n",
    "    '''\n",
    "    output = pd.DataFrame()\n",
    "    sentiment = df.loc[:, 'I1_lag1':'I10_lag47']\n",
    "    for i in tqdm(range(1, 11)):\n",
    "        col_name = \"I{}\".format(str(i))\n",
    "        start, end = col_name + \"_lag1\", col_name + \"_lag47\"\n",
    "        theme_data = sentiment.loc[:, start:end]\n",
    "        output[col_name+\"_max\"] = theme_data.max(axis=1)\n",
    "        output[col_name+\"_min\"] = theme_data.min(axis=1)\n",
    "        output[col_name+\"_mean\"] = theme_data.mean(axis=1)\n",
    "        output[col_name+\"_median\"] = theme_data.median(axis=1)\n",
    "        output[col_name+\"_trend\"] = theme_data.apply(get_trend_of_ts, axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# Get the max, min, median, mean and trend of sentiment\n",
    "sentiment = get_mean_max_min_median_trend_sentiment(df)\n",
    "# Concatenate X1-X5 with sentiment feature\n",
    "train = pd.concat([df.loc[:, 'X1':\"X5\"], sentiment], axis=1)\n",
    "\n",
    "# split data into trainning data and validation data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, Y,  \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "\n",
    "parameter_grid = {\"C\":[0.6, 0.7, 0.8, 0.9, 1]}\n",
    "simple_model = GridSearchCV(LogisticRegression(), param_grid=parameter_grid,\n",
    "                            n_jobs=-1)\n",
    "simple_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_valid, simple_model.predict(x_valid)))\n",
    "print(accuracy_score(y_valid, simple_model.predict(x_valid)))\n",
    "print(log_loss(y_valid, simple_model.predict_proba(x_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment, X1-X5 and cross comparison\n",
    "\n",
    "- Use X1-X5, \n",
    "- max, min, median, mean, trend of sentiment data, \n",
    "- cross comparison of X1-X5 (E.X. whether X1 > X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82091\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.31      0.36       627\n",
      "           1       0.53      0.69      0.60       760\n",
      "           2       0.46      0.40      0.43       713\n",
      "\n",
      "    accuracy                           0.48      2100\n",
      "   macro avg       0.47      0.47      0.46      2100\n",
      "weighted avg       0.47      0.48      0.47      2100\n",
      "\n",
      "0.48\n",
      "1.0292395875960232\n"
     ]
    }
   ],
   "source": [
    "def add_cross_comparison(df):\n",
    "    '''\n",
    "    compare Xi with Xj, if Xi > Xj, then the value of new column \"XiXj\" is 1, else 0 \n",
    "    '''\n",
    "    for i in range(1, 6):\n",
    "        for j in range(1, 6):\n",
    "            col1, col2 = \"X{}\".format(str(i)), \"X{}\".format(str(j))\n",
    "            df[col1+col2] = df[col1] > df[col2]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Concatenate X1-X5 with sentiment feature\n",
    "df = pd.concat([df.loc[:, 'X1':\"X5\"], sentiment], axis=1)\n",
    "# Add cross comparison feature\n",
    "df = add_cross_comparison(df)\n",
    "\n",
    "# split data into trainning data and validation data\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(df, Y,  \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "\n",
    "parameter_grid = {\"C\":[0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
    "simple_model = GridSearchCV(LogisticRegression(), param_grid=parameter_grid,\n",
    "                            n_jobs=-1)\n",
    "simple_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_valid, simple_model.predict(x_valid)))\n",
    "print(accuracy_score(y_valid, simple_model.predict(x_valid)))\n",
    "print(log_loss(y_valid, simple_model.predict_proba(x_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>Output submission file into the desired format</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:33<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Read test file\n",
    "test_filename = './input_data/input_test_PkjtqdQ.csv'\n",
    "df = pd.read_csv(test_filename).iloc[:, 1:]\n",
    "\n",
    "# Get the max, min, median, mean and trend of sentiment\n",
    "sentiment = get_mean_max_min_median_trend_sentiment(df)\n",
    "df = pd.concat([df.loc[:, 'X1':\"X5\"], sentiment], axis=1)\n",
    "\n",
    "# add the cross comparison features\n",
    "df_with_cross_comparison = add_cross_comparison(df)\n",
    "\n",
    "# Predict probability of test data\n",
    "output = simple_model.predict_proba(df_with_cross_comparison)\n",
    "output = pd.DataFrame(output, columns=['Target -1', 'Target 0', 'Target 1'])\n",
    "output.to_csv(\"./output_data/lr_sentiment_crossComparison.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
